{
  "responsable_rh": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 116,
    "confused_with": {}
  },
  "action_type": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 27,
    "confused_with": {}
  },
  "nature_contrat": {
    "precision": 0.9318181818181818,
    "recall": 0.9761904761904762,
    "f1-score": 0.9534883720930233,
    "support": 42,
    "confused_with": {}
  },
  "date_debut": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 16,
    "confused_with": {}
  },
  "duree_contrat": {
    "precision": 0.8947368421052632,
    "recall": 1.0,
    "f1-score": 0.9444444444444444,
    "support": 34,
    "confused_with": {}
  },
  "nom_encadreur": {
    "precision": 0.9897959183673469,
    "recall": 1.0,
    "f1-score": 0.9948717948717948,
    "support": 194,
    "confused_with": {}
  },
  "justification": {
    "precision": 1.0,
    "recall": 0.994061757719715,
    "f1-score": 0.9970220369267422,
    "support": 842,
    "confused_with": {}
  },
  "date_fin": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 8,
    "confused_with": {}
  },
  "nom_poste": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 172,
    "confused_with": {}
  },
  "date_mise_en_service": {
    "precision": 0.9882352941176471,
    "recall": 1.0,
    "f1-score": 0.9940828402366864,
    "support": 84,
    "confused_with": {}
  },
  "nom_validateur": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 483,
    "confused_with": {}
  },
  "commentaire": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 106,
    "confused_with": {}
  },
  "poids": {
    "precision": 1.0,
    "recall": 0.9008264462809917,
    "f1-score": 0.9478260869565218,
    "support": 121,
    "confused_with": {}
  },
  "objectif": {
    "precision": 1.0,
    "recall": 0.9095238095238095,
    "f1-score": 0.9526184538653367,
    "support": 630,
    "confused_with": {}
  },
  "action_demandee": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 25,
    "confused_with": {}
  },
  "intention_demande": {
    "precision": 0.99581589958159,
    "recall": 1.0,
    "f1-score": 0.9979035639412999,
    "support": 238,
    "confused_with": {}
  },
  "situation_budget": {
    "precision": 0.9545454545454546,
    "recall": 0.9333333333333333,
    "f1-score": 0.9438202247191012,
    "support": 45,
    "confused_with": {}
  },
  "nom_flux": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 105,
    "confused_with": {}
  },
  "type_demande": {
    "precision": 0.9973821989528796,
    "recall": 1.0,
    "f1-score": 0.998689384010485,
    "support": 381,
    "confused_with": {}
  },
  "exploitation": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 253,
    "confused_with": {}
  },
  "direction": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 148,
    "confused_with": {}
  },
  "id_demande": {
    "precision": 1.0,
    "recall": 0.9606741573033708,
    "f1-score": 0.9799426934097422,
    "support": 178,
    "confused_with": {
      "type_demande": 1
    }
  },
  "poste_encadreur": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 12,
    "confused_with": {}
  },
  "resultat": {
    "precision": 1.0,
    "recall": 0.7660753880266076,
    "f1-score": 0.8675455116133083,
    "support": 902,
    "confused_with": {}
  },
  "motif": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 67,
    "confused_with": {}
  },
  "effectif": {
    "precision": 0.875,
    "recall": 1.0,
    "f1-score": 0.9333333333333333,
    "support": 7,
    "confused_with": {}
  },
  "dotation": {
    "precision": 1.0,
    "recall": 0.9831460674157303,
    "f1-score": 0.9915014164305949,
    "support": 178,
    "confused_with": {}
  },
  "info_type": {
    "precision": 0.9347826086956522,
    "recall": 1.0,
    "f1-score": 0.9662921348314606,
    "support": 43,
    "confused_with": {}
  },
  "micro avg": {
    "precision": 0.9965224111282844,
    "recall": 0.9452079897379513,
    "f1-score": 0.9701871532022948,
    "support": 5457
  },
  "macro avg": {
    "precision": 0.9843611570780005,
    "recall": 0.9794225512783584,
    "f1-score": 0.9808350818458526,
    "support": 5457
  },
  "weighted avg": {
    "precision": 0.9968612037139478,
    "recall": 0.9452079897379513,
    "f1-score": 0.9681135163770387,
    "support": 5457
  },
  "accuracy": 0.9760751059963658
}